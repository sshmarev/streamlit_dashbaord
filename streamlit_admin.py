# streamlit_admin.py (—Ñ–∏–Ω–∞–ª—å–Ω–∞—è, –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)

import streamlit as st
import asyncpg
import pandas as pd
import asyncio
from datetime import date, timedelta
import altair as alt
import plotly.express as px
import plotly.graph_objects as go
from funnel_logic import fetch_funnel_stats, _fetch_trial_retention_cohorts

st.set_page_config(layout="wide")

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î ===
DB_URL = st.secrets["DATABASE_URL"]

# --- –£–ü–†–ê–í–õ–ï–ù–ò–ï –¶–ò–ö–õ–û–ú ASYNCIO ---

@st.cache_resource
def get_event_loop():
    try:
        return asyncio.get_running_loop()
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        return loop

@st.cache_resource
def get_db_pool(_loop):
    return _loop.run_until_complete(asyncpg.create_pool(dsn=DB_URL, loop=_loop))

loop = get_event_loop()
pool = get_db_pool(loop)

# --- –ê–°–ò–ù–•–†–û–ù–ù–´–ï –§–£–ù–ö–¶–ò–ò ---
# (–û–Ω–∏ –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
async def _fetch_user_stats(pool):
    async with pool.acquire() as conn:
        rows = await conn.fetch('''
            SELECT date_trunc('day', created_at)::date AS day,
                   COUNT(*) FILTER (WHERE is_blocked IS DISTINCT FROM true) AS new_active,
                   COUNT(*) FILTER (WHERE is_blocked = true) AS new_blocked
            FROM users GROUP BY day ORDER BY day
        ''')
    df = pd.DataFrame(rows, columns=["day", "new_active", "new_blocked"])
    if not df.empty:
        df['day'] = pd.to_datetime(df['day'])
        df = df.sort_values("day").set_index("day")
        df = df.resample('D').sum().fillna(0).reset_index()
        df["active_users"] = df["new_active"].cumsum()
        df["blocked_users"] = -df["new_blocked"].cumsum()
    return df

async def _fetch_sources(pool):
    async with pool.acquire() as conn:
        rows = await conn.fetch("SELECT DISTINCT source FROM users WHERE source IS NOT NULL ORDER BY source")
    return ["–≤—Å–µ"] + [row["source"] for row in rows]

async def _fetch_retention_cohorts(pool):
    async with pool.acquire() as conn:
        rows = await conn.fetch('''
            WITH user_cohorts AS (
                SELECT id AS user_id, date_trunc('week', created_at)::date AS cohort_week FROM users
            ), user_activity AS (
                SELECT DISTINCT user_id, date_trunc('week', created_at)::date AS activity_week FROM meals
            )
            SELECT
                c.cohort_week,
                FLOOR((a.activity_week - c.cohort_week) / 7) AS week_number,
                COUNT(DISTINCT c.user_id) AS retained_users
            FROM user_cohorts c JOIN user_activity a ON c.user_id = a.user_id AND a.activity_week >= c.cohort_week
            GROUP BY c.cohort_week, week_number ORDER BY c.cohort_week, week_number
        ''')
    return pd.DataFrame(rows, columns=['cohort_week', 'week_number', 'retained_users'])

async def _fetch_paid_growth(pool, start_date, end_date):
    async with pool.acquire() as conn:
        rows = await conn.fetch('''
            SELECT date_trunc('day', starts_at)::date AS day, COUNT(*) AS new_subs
            FROM subscriptions WHERE is_active = TRUE AND starts_at::date BETWEEN $1 AND $2
            GROUP BY day ORDER BY day
        ''', start_date, end_date)
    return pd.DataFrame(rows, columns=["day", "new_subs"])

async def _fetch_arppu(pool, start_date, end_date):
    async with pool.acquire() as conn:
        return await conn.fetchval('''
            SELECT AVG(amount_cents) FROM subscriptions
            WHERE is_active = TRUE AND starts_at::date BETWEEN $1 AND $2
        ''', start_date, end_date)

async def _fetch_active_subscriptions_over_time(pool):
    async with pool.acquire() as conn:
        has_subs = await conn.fetchval("SELECT EXISTS (SELECT 1 FROM subscriptions)")
        if not has_subs:
            return pd.DataFrame(columns=["day", "active_subs"])
        
        rows = await conn.fetch('''
            SELECT day::date, COUNT(*) AS active_subs
            FROM generate_series(
                     (SELECT MIN(starts_at)::date FROM subscriptions),
                     CURRENT_DATE, interval '1 day'
                 ) AS day
            JOIN subscriptions s ON day >= s.starts_at::date AND day < s.ends_at::date
            WHERE s.is_active = TRUE GROUP BY day ORDER BY day
        ''')
    return pd.DataFrame(rows, columns=["day", "active_subs"])

async def _fetch_active_users_by_period(pool, days):
    """–°—á–∏—Ç–∞–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –¥–Ω–µ–π."""
    async with pool.acquire() as conn:
        query = '''
            SELECT COUNT(DISTINCT user_id)
            FROM meals
            WHERE created_at >= NOW() - INTERVAL '$1 days'
        '''
        # –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: $1 –≤ —Å—Ç—Ä–æ–∫–µ INTERVAL - —ç—Ç–æ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å asyncpg
        # –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –≤—Å—Ç–∞–≤–∫–∏ —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ —Ç–∞–∫–∏–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏.
        return await conn.fetchval(query.replace('$1', str(days)))

async def _fetch_active_users_over_time(pool, period='day'):
    """–°—á–∏—Ç–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –ø–æ –ø–µ—Ä–∏–æ–¥–∞–º."""
    # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–µ—Ä–∏–æ–¥ - –æ–¥–Ω–æ –∏–∑ –¥–æ–ø—É—Å—Ç–∏–º—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    if period not in ['day', 'week', 'month']:
        period = 'day'
        
    async with pool.acquire() as conn:
        rows = await conn.fetch(f'''
            SELECT
                date_trunc('{period}', created_at)::date AS period_start,
                COUNT(DISTINCT user_id) AS active_users
            FROM meals
            GROUP BY period_start
            ORDER BY period_start
        ''')
    df = pd.DataFrame(rows, columns=['period_start', 'active_users'])
    if not df.empty:
        df = df.set_index('period_start')
    return df

async def _fetch_meals_stats_over_time(pool, period='day'):
    """–°—á–∏—Ç–∞–µ—Ç –æ–±—â–µ–µ –∏ —Å—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–µ–º–æ–≤ –ø–∏—â–∏ –ø–æ –ø–µ—Ä–∏–æ–¥–∞–º."""
    if period not in ['day', 'week', 'month']:
        period = 'day'
        
    async with pool.acquire() as conn:
        rows = await conn.fetch(f'''
            SELECT
                date_trunc('{period}', created_at)::date AS period_start,
                COUNT(id) AS total_meals,
                COUNT(DISTINCT user_id) AS active_users
            FROM meals
            GROUP BY period_start
            ORDER BY period_start
        ''')
    df = pd.DataFrame(rows, columns=['period_start', 'total_meals', 'active_users'])
    if not df.empty:
        # –°—á–∏—Ç–∞–µ–º —Å—Ä–µ–¥–Ω–µ–µ, –∏–∑–±–µ–≥–∞—è –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å
        df['avg_meals_per_user'] = df.apply(
            lambda row: row['total_meals'] / row['active_users'] if row['active_users'] > 0 else 0,
            axis=1
        )
        df = df.set_index('period_start')
    return df

async def _fetch_total_active_users(pool):
    """–°—á–∏—Ç–∞–µ—Ç –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ù–ï –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π."""
    async with pool.acquire() as conn:
        return await conn.fetchval('SELECT COUNT(*) FROM users WHERE is_blocked IS DISTINCT FROM TRUE')

async def _fetch_total_paying_users(pool):
    """–°—á–∏—Ç–∞–µ—Ç –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –∞–∫—Ç–∏–≤–Ω–æ–π –ø–æ–¥–ø–∏—Å–∫–æ–π."""
    async with pool.acquire() as conn:
        return await conn.fetchval('SELECT COUNT(*) FROM subscriptions WHERE is_active = TRUE')

# --- –°–ò–ù–•–†–û–ù–ù–´–ï –û–ë–ï–†–¢–ö–ò –° –ö–ï–®–ò–†–û–í–ê–ù–ò–ï–ú ---

@st.cache_data(ttl=600)
def fetch_user_stats_cached():
    return loop.run_until_complete(_fetch_user_stats(pool))

@st.cache_data(ttl=600)
def fetch_sources_cached():
    return loop.run_until_complete(_fetch_sources(pool))

@st.cache_data(ttl=600)
def fetch_funnel_stats_cached(sources, start_date, end_date):
    return loop.run_until_complete(fetch_funnel_stats(pool, sources, start_date, end_date))

@st.cache_data(ttl=600)
def fetch_retention_cohorts_cached():
    return loop.run_until_complete(_fetch_retention_cohorts(pool))

@st.cache_data(ttl=600)
def fetch_trial_retention_cohorts_cached():
    return loop.run_until_complete(_fetch_trial_retention_cohorts(pool))

@st.cache_data(ttl=600)
def fetch_paid_growth_cached(start_date, end_date):
    return loop.run_until_complete(_fetch_paid_growth(pool, start_date, end_date))

@st.cache_data(ttl=600)
def fetch_arppu_cached(start_date, end_date):
    return loop.run_until_complete(_fetch_arppu(pool, start_date, end_date))

@st.cache_data(ttl=600)
def fetch_active_subscriptions_over_time_cached():
    return loop.run_until_complete(_fetch_active_subscriptions_over_time(pool))

@st.cache_data(ttl=600)
def fetch_active_users_by_period_cached(days):
    return loop.run_until_complete(_fetch_active_users_by_period(pool, days))

@st.cache_data(ttl=600)
def fetch_active_users_over_time_cached(period='day'):
    return loop.run_until_complete(_fetch_active_users_over_time(pool, period))

@st.cache_data(ttl=600)
def fetch_meals_stats_over_time_cached(period='day'):
    return loop.run_until_complete(_fetch_meals_stats_over_time(pool, period))

@st.cache_data(ttl=60)
def fetch_total_active_users_cached():
    return loop.run_until_complete(_fetch_total_active_users(pool))

@st.cache_data(ttl=60)
def fetch_total_paying_users_cached():
    return loop.run_until_complete(_fetch_total_paying_users(pool))

# --- –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ—Ç—Ä–∏—Å–æ–≤–∫–∏ –≥—Ä–∞—Ñ–∏–∫–æ–≤ ---

def plot_funnel_plotly(data, avg_days):
    if not data or pd.DataFrame(data).empty:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≤–æ—Ä–æ–Ω–∫–∏ –∑–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥.")
        return

    df = pd.DataFrame(data)

    # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–µ —Ä–∞—Å—á—ë—Ç—ã –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤
    df = df.copy()
    total = float(df["count"].iloc[0]) if df["count"].iloc[0] else 0.0
    pct_total = []
    pct_prev = []
    prev = None
    for i, val in enumerate(df["count"].tolist()):
        # % –æ—Ç –æ–±—â–µ–≥–æ
        pct_total.append(round((val / total * 100.0), 1) if total > 0 else 0.0)
        # % –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ (–¥–ª—è –ø–µ—Ä–≤–æ–≥–æ —à–∞–≥–∞ —Å—á–∏—Ç–∞–µ–º 100%)
        if i == 0:
            pct_prev.append(100.0)
        else:
            pct_prev.append(round((val / prev * 100.0), 1) if prev and prev > 0 else 0.0)
        prev = val

    df["% –æ—Ç –æ–±—â–µ–≥–æ"] = pct_total
    df["% –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ"] = pct_prev

    fig = go.Figure(go.Funnel(
        y=df["stage"],
        x=df["count"],
        textposition="inside",
        constraintext='inside',
        textfont=dict(size=12, color='white'),
        # –¥–≤–µ –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ customdata: [pct_prev, pct_total]
        customdata=df[["% –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ", "% –æ—Ç –æ–±—â–µ–≥–æ"]],
        texttemplate="<b>%{value}</b><br>%{customdata[0]:.1f}% –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ<br><i>%{customdata[1]:.1f}% –æ—Ç –≤—Å–µ—Ö</i>",
    ))

    title = f"üîª –í–æ—Ä–æ–Ω–∫–∞: –ø—É—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–≤ —Å—Ä–µ–¥–Ω–µ–º {avg_days} –¥–Ω. –¥–æ –ø–æ–∫—É–ø–∫–∏)" if avg_days else "üîª –í–æ—Ä–æ–Ω–∫–∞: –ø—É—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"
    fig.update_layout(title_text=title, height=600, margin=dict(l=200, r=50, t=50, b=50))
    st.plotly_chart(fig, use_container_width=True)

def plot_retention_heatmap(df):
    import plotly.express as px

    if df.empty or 'cohort_week' not in df.columns:
        st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∫–æ–≥–æ—Ä—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.")
        return

    cohort_sizes = df[df['week_number'] == 0].set_index('cohort_week')['retained_users']
    if cohort_sizes.empty:
        st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Ä–∞–∑–º–µ—Ä–æ–≤ –∫–æ–≥–æ—Ä—Ç.")
        return

    df = df.copy()
    df['cohort_size'] = df['cohort_week'].map(cohort_sizes)
    df['retention'] = (df['retained_users'] / df['cohort_size']) * 100

    # –ü–†–û–¶–ï–ù–¢–´ –¥–ª—è —Ü–≤–µ—Ç–∞
    retention_pivot = df.pivot_table(index='cohort_week', columns='week_number', values='retention')
    # –ê–ë–°–û–õ–Æ–¢–ù–´–ï –¥–ª—è —Ç–µ–∫—Å—Ç–∞
    absolute_pivot = df.pivot_table(index='cohort_week', columns='week_number', values='retained_users')

    # –ü–æ–¥–ø–∏—Å–∏ –≤–∏–¥–∞ "12.3% (5)"
    text_matrix = [
        [
            "" if pd.isna(retention_pivot.loc[idx, col]) else f"{retention_pivot.loc[idx, col]:.1f}% ({int(absolute_pivot.loc[idx, col])})"
            for col in retention_pivot.columns
        ]
        for idx in retention_pivot.index
    ]

    # –ö—Ä–∞—Å–∏–≤—ã–µ –º–µ—Ç–∫–∏ –∏–Ω–¥–µ–∫—Å–∞
    try:
        retention_pivot.index = pd.to_datetime(retention_pivot.index).strftime('%Y-%m-%d')
    except Exception:
        pass  # –µ—Å–ª–∏ —É–∂–µ —Å—Ç—Ä–æ–∫–∏ ‚Äî –æ—Å—Ç–∞–≤–∏–º –∫–∞–∫ –µ—Å—Ç—å

    fig = px.imshow(
        retention_pivot,
        labels=dict(x="–ù–µ–¥–µ–ª—è –ø–æ—Å–ª–µ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏", y="–ö–æ–≥–æ—Ä—Ç–∞ (–Ω–µ–¥–µ–ª—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏)", color="–£–¥–µ—Ä–∂–∞–Ω–∏–µ, %"),
        title="üó∫Ô∏è –ö–æ–≥–æ—Ä—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —É–¥–µ—Ä–∂–∞–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π (–ø–æ –Ω–µ–¥–µ–ª—è–º)",
        color_continuous_scale='Blues',
        range_color=[0, 100],
        aspect="auto"
    )

    fig.update_traces(text=text_matrix, texttemplate="%{text}", textfont_size=9)

    # üîë –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –≤—ã—Å–æ—Ç–∞
    num_rows = retention_pivot.shape[0]  # –ª–∏–±–æ: df['cohort_week'].nunique()
    row_height = 30  # –ø–æ–¥—Å—Ç—Ä–æ–π –ø–æ –≤–∫—É—Å—É (25‚Äì35)
    fig.update_layout(height=max(300, num_rows * row_height),
                      margin=dict(l=100, r=50, t=50, b=50))

    fig.update_xaxes(side="top")
    st.plotly_chart(fig, use_container_width=True)


def plot_trial_retention_heatmap(df):
    import plotly.express as px
    # –æ–∂–∏–¥–∞–µ–º, —á—Ç–æ –µ—Å—Ç—å: import pandas as pd, import streamlit as st

    if df.empty or not {'cohort_day', 'day_number', 'retained_users'}.issubset(df.columns):
        st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —É–¥–µ—Ä–∂–∞–Ω–∏—è –ø–æ —Ç—Ä–∏–∞–ª—É.")
        return

    df = df.copy()

    # cohort_size –∫–∞–∫ –≤ —Å—Ç–∞—Ä–æ–π –ª–æ–≥–∏–∫–µ: –±–µ—Ä–µ–º retained_users –Ω–∞ day 0
    sizes = df[df['day_number'] == 0].set_index('cohort_day')['retained_users']
    if sizes.empty:
        # –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç, —á—Ç–æ–±—ã –≥—Ä–∞—Ñ–∏–∫ –Ω–µ –ø–∞–¥–∞–ª, –µ—Å–ª–∏ day 0 –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç
        sizes = df.groupby('cohort_day')['retained_users'].max()

    df['cohort_size'] = df['cohort_day'].map(sizes).astype(float)
    df['retention'] = (df['retained_users'] / df['cohort_size']).replace([float('inf'), -float('inf')], 0).fillna(0) * 100

    # —Å–≤–æ–¥–Ω—ã–µ: –ø—Ä–æ—Ü–µ–Ω—Ç—ã –¥–ª—è —Ü–≤–µ—Ç–∞, –∞–±—Å–æ–ª—é—Ç—ã –¥–ª—è –ø–æ–¥–ø–∏—Å–∏
    retention_pivot = df.pivot_table(index='cohort_day', columns='day_number', values='retention')
    absolute_pivot  = df.pivot_table(index='cohort_day', columns='day_number', values='retained_users')

    # —É–ø–æ—Ä—è–¥–æ—á–∏–º –∫–æ–ª–æ–Ω–∫–∏ 0..4
    cols = sorted([c for c in retention_pivot.columns if pd.notna(c)])
    retention_pivot = retention_pivot.reindex(columns=cols)
    absolute_pivot  = absolute_pivot.reindex(columns=cols)

    # –ø–æ–¥–ø–∏—Å–∏ "12.3% (5)"
    text_matrix = [
        [
            "" if pd.isna(retention_pivot.loc[idx, col])
            else f"{retention_pivot.loc[idx, col]:.1f}% ({int(absolute_pivot.loc[idx, col])})"
            for col in retention_pivot.columns
        ]
        for idx in retention_pivot.index
    ]

    # –∫—Ä–∞—Å–∏–≤—ã–µ –º–µ—Ç–∫–∏ –¥–∞—Ç
    try:
        retention_pivot.index = pd.to_datetime(retention_pivot.index).strftime('%b %d, %Y')
    except Exception:
        pass

    fig = px.imshow(
        retention_pivot,
        labels=dict(x="–î–µ–Ω—å –ø–æ—Å–ª–µ –Ω–∞—á–∞–ª–∞ —Ç—Ä–∏–∞–ª–∞ (0 = –¥–µ–Ω—å –∞–∫—Ç–∏–≤–∞—Ü–∏–∏)", y="–ö–æ–≥–æ—Ä—Ç–∞ (–¥–∞—Ç–∞ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏)", color="–£–¥–µ—Ä–∂–∞–Ω–∏–µ, %"),
        title="üéØ –£–¥–µ—Ä–∂–∞–Ω–∏–µ –≤ —Ä–∞–º–∫–∞—Ö 5-–¥–Ω–µ–≤–Ω–æ–≥–æ —Ç—Ä–∏–∞–ª–∞",
        color_continuous_scale='Greens',
        range_color=[0, 100],
        aspect="auto"
    )
    fig.update_traces(text=text_matrix, texttemplate="%{text}", textfont_size=9)
    fig.update_xaxes(side="top")

    # üîë –∞–≤—Ç–æ-–≤—ã—Å–æ—Ç–∞: –æ–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞ ‚âà 30 px
    num_rows = retention_pivot.shape[0]
    row_height = 30
    fig.update_layout(
        height=max(320, num_rows * row_height),
        margin=dict(l=110, r=50, t=60, b=50)
    )

    st.plotly_chart(fig, use_container_width=True)




# --- –ì–õ–ê–í–ù–´–ô –ö–û–î ---

st.title("üìä –ê–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å: –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –±–æ—Ç–∞")
with st.spinner("–ó–∞–≥—Ä—É–∂–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏..."):
    total_active = fetch_total_active_users_cached()
    total_paying = fetch_total_paying_users_cached()

col1, col2 = st.columns(2)
col1.metric("–í—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π", total_active or 0)
col2.metric("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –ø–æ–¥–ø–∏—Å–∫–æ–π", f"{total_paying or 0} üí≥")

st.markdown("---")
tab1, tab2 = st.tabs(["üí° –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –∏ –≤–æ—Ä–æ–Ω–∫–∞", "üí≥ –ú–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏—è"])

with tab1:
    st.header("üìà –î–∏–Ω–∞–º–∏–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π –±–∞–∑—ã")

    st.markdown("#### –ê–∫—Ç–∏–≤–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ (DAU/WAU/MAU)")
    col1, col2, col3 = st.columns(3)
    with col1:
        dau = fetch_active_users_by_period_cached(1)
        st.metric("–ó–∞ –¥–µ–Ω—å (DAU)", dau or 0)
    with col2:
        wau = fetch_active_users_by_period_cached(7)
        st.metric("–ó–∞ –Ω–µ–¥–µ–ª—é (WAU)", wau or 0)
    with col3:
        mau = fetch_active_users_by_period_cached(30)
        st.metric("–ó–∞ –º–µ—Å—è—Ü (MAU)", mau or 0)

    with st.spinner("–ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è—Ö..."):
        users_df = fetch_user_stats_cached()
    
    if not users_df.empty:
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("#### –ù–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω–æ")
            melted_cumulative = users_df.melt(id_vars="day", value_vars=["active_users", "blocked_users"], var_name="type", value_name="count")
            chart_cumulative = alt.Chart(melted_cumulative).mark_line().encode(x="day:T", y="count:Q", color="type:N", tooltip=['day', 'type', 'count']).interactive()
            st.altair_chart(chart_cumulative, use_container_width=True)
        with col2:
            st.markdown("#### –ü—Ä–∏—Ä–æ—Å—Ç –ø–æ –¥–Ω—è–º")
            melted_daily = users_df.melt(id_vars="day", value_vars=["new_active", "new_blocked"], var_name="type", value_name="count")
            chart_daily = alt.Chart(melted_daily).mark_bar().encode(x="day:T", y="count:Q", color="type:N", tooltip=['day', 'type', 'count']).interactive()
            st.altair_chart(chart_daily, use_container_width=True)
    else:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è—Ö.")

    st.markdown("<hr>", unsafe_allow_html=True)
    st.header("üçî –î–∏–Ω–∞–º–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–∏–µ–º–æ–≤ –ø–∏—â–∏")

    meals_period_options = {'–ü–æ –¥–Ω—è–º': 'day', '–ü–æ –Ω–µ–¥–µ–ª—è–º': 'week', '–ü–æ –º–µ—Å—è—Ü–∞–º': 'month'}
    meals_selected_period_label = st.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ –ø–µ—Ä–∏–æ–¥ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏:",
        options=list(meals_period_options.keys()),
        key="meals_period_selector" # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á –¥–ª—è —ç—Ç–æ–≥–æ —Å–µ–ª–µ–∫—Ç–±–æ–∫—Å–∞
    )
    meals_selected_period = meals_period_options[meals_selected_period_label]

    with st.spinner(f"–ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ –ø—Ä–∏–µ–º–∞—Ö –ø–∏—â–∏..."):
        meals_stats_df = fetch_meals_stats_over_time_cached(meals_selected_period)

    if not meals_stats_df.empty:
        # –í—ã–±–æ—Ä, —á—Ç–æ –æ—Ç–æ–±—Ä–∞–∂–∞—Ç—å –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–µ
        display_option = st.radio(
            "–ü–æ–∫–∞–∑–∞—Ç—å –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–µ:",
            ["–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ", "–°—Ä–µ–¥–Ω–µ–µ –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"],
            horizontal=True
        )

        if display_option == "–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ":
            st.line_chart(meals_stats_df['total_meals'])
        else:
            st.line_chart(meals_stats_df['avg_meals_per_user'])
    else:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–∏–µ–º–∞—Ö –ø–∏—â–∏ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞.")

    st.markdown("<hr>", unsafe_allow_html=True)
    st.header("üîª –í–æ—Ä–æ–Ω–∫–∞ –∫–æ–Ω–≤–µ—Ä—Å–∏–∏")
    
    sources = fetch_sources_cached()
    selected_sources = st.multiselect("–ò—Å—Ç–æ—á–Ω–∏–∫–∏ (source):", sources, default=["–≤—Å–µ"])
    query_sources = [] if "–≤—Å–µ" in selected_sources else selected_sources
    
    # --- –ò–ó–ú–ï–ù–ï–ù–ò–ï 2: –î–æ–±–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–∞—Ç ---
    
    today = date.today()
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º session_state, –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
    if 'start_date' not in st.session_state:
        st.session_state.start_date = today - timedelta(days=6)
        st.session_state.end_date = today

    def set_date_range(start, end):
        st.session_state.start_date = start
        st.session_state.end_date = end

    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –¥–∞—Ç—ã –¥–ª—è –∫–Ω–æ–ø–æ–∫
    yesterday = today - timedelta(days=1)
    last_7_days_start = today - timedelta(days=6)
    this_month_start = today.replace(day=1)
    last_month_end = this_month_start - timedelta(days=1)
    last_month_start = last_month_end.replace(day=1)

    # –°–æ–∑–¥–∞–µ–º –∫–Ω–æ–ø–∫–∏
    col1, col2, col3, col4, col5 = st.columns(5)
    with col1:
        st.button("–°–µ–≥–æ–¥–Ω—è", on_click=set_date_range, args=(today, today), use_container_width=True)
    with col2:
        st.button("–í—á–µ—Ä–∞", on_click=set_date_range, args=(yesterday, yesterday), use_container_width=True)
    with col3:
        st.button("7 –¥–Ω–µ–π", on_click=set_date_range, args=(last_7_days_start, today), use_container_width=True)
    with col4:
        st.button("–≠—Ç–æ—Ç –º–µ—Å—è—Ü", on_click=set_date_range, args=(this_month_start, today), use_container_width=True)
    with col5:
        st.button("–ü—Ä–æ—à–ª—ã–π –º–µ—Å—è—Ü", on_click=set_date_range, args=(last_month_start, last_month_end), use_container_width=True)
    
    # –í–∏–¥–∂–µ—Ç—ã –¥–ª—è –≤—ã–±–æ—Ä–∞ –¥–∞—Ç, —É–ø—Ä–∞–≤–ª—è–µ–º—ã–µ —á–µ—Ä–µ–∑ session_state
    start_date = st.date_input("–ù–∞—á–∞–ª–æ –ø–µ—Ä–∏–æ–¥–∞", key="start_date")
    end_date = st.date_input("–ö–æ–Ω–µ—Ü –ø–µ—Ä–∏–æ–¥–∞", key="end_date")

    if start_date > end_date:
        st.error("–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–∑–∂–µ –¥–∞—Ç—ã –æ–∫–æ–Ω—á–∞–Ω–∏—è.")
    else:
        with st.spinner("–°—Ç—Ä–æ–∏–º –≤–æ—Ä–æ–Ω–∫—É..."):
            funnel_result = fetch_funnel_stats_cached(query_sources, start_date, end_date)
        
        # –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º –≥—Ä–∞—Ñ–∏–∫ –≤ –∫–æ–ª–æ–Ω–∫–∏, —á—Ç–æ–±—ã —Å—É–∑–∏—Ç—å –µ–≥–æ
        col1, col2, col3 = st.columns([0.5, 2, 0.5])
        with col2:
            plot_funnel_plotly(funnel_result["funnel"], funnel_result["avg_days"])

    st.markdown("<hr>", unsafe_allow_html=True)
    st.header("üìà –î–∏–Ω–∞–º–∏–∫–∞ –ê–∫—Ç–∏–≤–Ω—ã—Ö –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")

    period_options = {'–ü–æ –¥–Ω—è–º (DAU)': 'day', '–ü–æ –Ω–µ–¥–µ–ª—è–º (WAU)': 'week', '–ü–æ –º–µ—Å—è—Ü–∞–º (MAU)': 'month'}
    selected_period_label = st.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ –ø–µ—Ä–∏–æ–¥ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏:",
        options=list(period_options.keys())
    )
    selected_period = period_options[selected_period_label]

    with st.spinner(f"–ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ–± –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è—Ö..."):
        active_users_df = fetch_active_users_over_time_cached(selected_period)

    if not active_users_df.empty:
        st.line_chart(active_users_df)
    else:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ–± –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞.")

    st.markdown("<hr>", unsafe_allow_html=True)
    st.header("üó∫Ô∏è –£–¥–µ—Ä–∂–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π (Retention)")
    with st.spinner("–°—á–∏—Ç–∞–µ–º –∫–æ–≥–æ—Ä—Ç—ã..."):
        retention_df = fetch_retention_cohorts_cached()
    plot_retention_heatmap(retention_df)

    st.markdown("<hr>", unsafe_allow_html=True)
    st.header("üéØ –£–¥–µ—Ä–∂–∞–Ω–∏–µ –≤ —Ä–∞–º–∫–∞—Ö 5-–¥–Ω–µ–≤–Ω–æ–≥–æ —Ç—Ä–∏–∞–ª–∞")
    with st.spinner("–°—á–∏—Ç–∞–µ–º –∫–æ–≥–æ—Ä—Ç—ã —Ç—Ä–∏–∞–ª–∞..."):
        trial_retention_df = fetch_trial_retention_cohorts_cached()
    plot_trial_retention_heatmap(trial_retention_df)


with tab2:
    st.header("üí∏ –ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –º–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏–∏")
    
    m_today = date.today()
    m_start_date = st.date_input("–ù–∞—á–∞–ª–æ –ø–µ—Ä–∏–æ–¥–∞", value=m_today - timedelta(days=29), key="m_start")
    m_end_date = st.date_input("–ö–æ–Ω–µ—Ü –ø–µ—Ä–∏–æ–¥–∞", value=m_today, key="m_end")
    
    if m_start_date > m_end_date:
        st.error("–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–∑–∂–µ –¥–∞—Ç—ã –æ–∫–æ–Ω—á–∞–Ω–∏—è.")
    else:
        st.markdown("#### üíπ –Æ–Ω–∏—Ç-—ç–∫–æ–Ω–æ–º–∏–∫–∞")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            marketing_spend = st.number_input("–í–≤–µ–¥–∏—Ç–µ –∑–∞—Ç—Ä–∞—Ç—ã –Ω–∞ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥ –∑–∞ –ø–µ—Ä–∏–æ–¥ ($)", min_value=0.0, step=10.0)
        
        with st.spinner("–°—á–∏—Ç–∞–µ–º —é–Ω–∏—Ç-—ç–∫–æ–Ω–æ–º–∏–∫—É..."):
            df_growth = fetch_paid_growth_cached(m_start_date, m_end_date)
            new_subscribers = df_growth['new_subs'].sum()
            arppu_cents = fetch_arppu_cached(m_start_date, m_end_date)
        
        with col2:
            cac = (marketing_spend / new_subscribers) if new_subscribers > 0 else 0
            st.metric("CAC (Cost per Acquisition)", f"${cac:.2f}")

        with col3:
            arppu = (arppu_cents / 100) if arppu_cents else 0
            st.metric("ARPPU (Average Revenue Per Paying User)", f"${arppu:.2f}")

        st.markdown("<hr>", unsafe_allow_html=True)
        st.header("üìà –î–∏–Ω–∞–º–∏–∫–∞ –ø–ª–∞—Ç–Ω—ã—Ö –ø–æ–¥–ø–∏—Å–æ–∫")

        with st.spinner("–ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ –ø–æ–¥–ø–∏—Å–∫–∞—Ö..."):
            subs_df = fetch_active_subscriptions_over_time_cached()
        
        if not subs_df.empty:
            st.markdown("#### –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–¥–ø–∏—Å–æ–∫")
            st.line_chart(subs_df.set_index('day'))
            st.markdown("#### –ü—Ä–∏—Ä–æ—Å—Ç –Ω–æ–≤—ã—Ö –ø–ª–∞—Ç–Ω—ã—Ö –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤ –ø–æ –¥–Ω—è–º")
            st.bar_chart(df_growth.set_index('day'))
        else:
            st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –ø–æ–¥–ø–∏—Å–∫–∞—Ö.")